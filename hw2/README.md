# Описание

Прошло пол года с момента, когда в вашу дверь постучал менеджер из маркетинга Марк со своим первым заданием. 
Подготовленные данные не только дали возможность запустить успешную маркетинговую компанию, 
но и стали фундаментом для целого нового маркетингового направления.
Теперь ваш код уже не просто стал кодом "для эксперимента", а одной из важных компонент коммерческого успеха компании.
А значит, настало время инвестировать силы в то, чтобы ваш код был надежен и готов к будущим изменениям!

Посовещавшись с архитектором Арчи, Марк попросил вас добавить в проект следующее:
1. Ваш авторитет в компании высок, но даже лучшие из нас иногда ошибаются. 
Поэтому вам нужно **покрыть тестами ваши UDF-функции**, чтобы при будущих доработках не возникло проблем.
1. Мы не очень доверяем парсеру (он ведь и так не каждый раз корректно парсит комментарии). 
Поэтому нужно контролировать, что количество "битых" записей в датасете комментариев не превышает 50%. 
Для этого нужно добавить **проверку качества данных для датасета `UScomments.csv`**.
1. Ну и раз уж мы занялись качеством данных, нужно проверить, что при считывании в режиме `DROPMALFORMED` мы получаем данные,
соответствующие следующим требованиям:
   1. Корректная схема данных
   2. Корректные идентификаторы видео (по содержанию спецсимволов и длине)
   3. Корректные значения в полях likes и replies: все значения >= 0 и есть хотя бы одно значение > 0

# Критерии выполнения

1. В качестве результата должна быть выслана ссылка на публичный git-репозиторий, созданный на основе репозитория, указанного в описании.
2. Код функций должен находить в папке video_analytics.
1. Код тестов для функций должен находиться в папке tests.
2. Код тестов для качества данных должен находиться в папке data_quality. Там уже есть пример для датасета USvideos.csv.
2. Тесты функций должны запускаться командой `poetry run pytest`
3. При запуске тестов не происходит пересоздания сессии спарка для каждого отдельного теста (используются fixtures). 
Можно использовать разные фикстуры для тестов функций и тестов качетсва данных.

# Примечания

- Для выполнения этого ДЗ вам потребуется компьютер с установленным Poetry - https://python-poetry.org/docs/#installation 
- Для установки зависимостей используйте команду `poetry install` из корня проекта.
- В этом задании scala-функция для тэгов не используется, чтобы не усложнять задание возней с зависимостями.
Вместо неё протестируйте вашу собственную реализацию, с которой вы сравнивали производительность в первом задании.
- Пример с тестами, демонстрировавшийся на занятии - https://github.com/Gorini4/pyspark_tests
- В качестве вдохновения для написания проверок качества данных можно сначала ознакомиться с этим примером -
https://github.com/sodadata/soda-core/blob/main/examples/pandas_dask_example.py
- При запуске проверок Soda важно убедиться, что тесты успешны, потому что все проверки успешны, 
а не потому что проверок нет (например, при неправильном пути к YAML-файлу проверок). 
Для этого можно специально "сломать" одну из проверок, как в примере с videos. 
- В п. 2 раздела "Описание" для чтения датаеста комментариев нужно использовать команду со следующими параметрами

```python
comments = spark.read.option('header', 'true').schema(comments_schema) \
.option("mode", "PERMISSIVE").option("columnNameOfCorruptRecord", "corrupt_record").csv('datasets/UScomments.csv')
```
- В п. 3 раздела "Описание" для чтения датаеста комментариев нужно использовать команду со следующими параметрами

```python
comments = spark.read.option('header', 'true').option("mode", "DROPMALFORMED").schema(comments_schema).csv('datasets/UScomments.csv')
```

